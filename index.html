<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="keywords" content="SHENGENG TANG, 唐申庚"> 
<meta name="description" content="SHENGENG TANG&#39;s home page">
<link rel="stylesheet" href="./configs/style/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>Shengeng Tang</title>
</head>

<body id="home">

<div id="layout-content" style="margin-top:25px">

<table>
<tbody>
  </tr>
  <tr>
    <td width="39%" valign="top" height="220" align='center'>
      <img height="210" id="photo" style="padding: 0pt 50pt 0pt 0pt; float: left; display: inline;" src="./configs/img/profile_02.jpg">
    </td>
    
    <td width="60%" valign="top" height="200">
      <b><font face="Times New Roman" size="6" color="#07689C">SHENGENG TANG </font><font size="6" face="华文行楷" color="#07689C"> &nbsp 唐申庚</font><font face="Times New Roman" size="6"></font></b> 
      <!-- <b><font face="Times New Roman" size="6" color="#07689C">SHENGENG TANG </font> &nbsp <img src="./configs/img/name_4.png" height="50px" style="margin-bottom:-18px"> -->
        <font face="Times New Roman" size="6"></font></b>
      <br><br>  
      <p>          
          Lecturer at Hefei University of Technology, Ph.D.
      </p>
      <p>
          School of Computer Science and Information Engineering (<a href="http://ci.hfut.edu.cn/" target="_blank">SCSIE</a>)
      </p>
      <p>          
          Hefei University of Technology (<a href="http://www.hfut.edu.cn/" target="_blank">HFUT</a>)
      </p>
      <p>          
          Email: tangsg&#64hfut.edu.cn
      </p>
      <p>          
          <!-- CV [<a href="./me/cv_en.pdf" target="_blank">English</a>] [<a href="./me/cv_cn.pdf" target="_blank">Chinese</a>]. View on <a href="https://github.com/tangshengeng"target="_blank">Github</a>. -->
	 Link: <a href="http://faculty.hfut.edu.cn/~AbI7Fz" target="_blank">Teaching Homepage</a>, <a href="https://scholar.google.com/citations?user=_JZcsnYAAAAJ" target="_blank">Google Scholar</a>, <a href="https://blog.csdn.net/m0_37369043" target="_blank">CSDN</a>, <a href="https://www.zhihu.com/column/c_1196038593297313792" target="_blank">ZHIHU</a>, <a href="https://github.com/tangshengeng" target="_blank">GitHub</a>
      </p>
    </td>
  </tr>
</tbody>
</table>

<br>
<div style="text-align:justify; text-align-last:justify; padding-left: 2.0em; padding-right: 2.0em;">
<a href="#biography"><b>Biography</b></a>
<a href="#researchs"><b>Reaserches</b></a>
<a href="#publications"><b>Publications</b></a>
<a href="#experience"><b>Experience</b></a>
<a href="#services"><b>Services</b></a>
<a href="#link"><b>Link</b></a>
</div>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">

<!-- ================ Biography ==================-->
<h2 id="biography">Biography</h2>
<p style="text-align:justify;">
<!--   I am a Ph.D student in Laboratory of Multimedia Computing (<a href="http://lmc.hfut.edu.cn/" target="_blank">LMC</a>), under the supervision of Prof. <a href="https://sites.google.com/site/homeofrichanghong/" target="_blank">Richang Hong (洪日昌)</a> and Prof. <a href="http://faculty.hfut.edu.cn/gd/zh_CN/" target="_blank">Dan Guo (郭丹)</a>. I received the B.E. degree from Hunan Normal University (<a href="http://www.hunnu.edu.cn/" target="_blank">HUNNU</a>) in 2017. My research interests include image processing and computer vision. Specifically, I focus on Continuous Sign Language Translation (CSLT). -->
  I earned my PhD degree (2022.12) from <a href="http://www.hfut.edu.cn/" target="_blank">Hefei University of Technology (HFUT)</a>, under the supervision of Prof. <a href="https://sites.google.com/site/homeofrichanghong/" target="_blank">Richang Hong (洪日昌)</a>. Before that, I received the B.E. degree from Hunan Normal University (<a href="http://www.hunnu.edu.cn/" target="_blank">HUNNU</a>) in 2017. My research interests include multimedia computing and computer vision. Specifically, I focus on Sign Language Translation (SLT) and Sign Language Production (SLP).
  <br><br>
  If you are interested in visual understanding and cross-media learning, please visit our homepage of the <a href="https://vut-hfut.github.io/" target="_blank">Visual Understanding Team</a>.
</p>

<!-- ================ Researches ==================-->
<h2 id="researches">Researches &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
     
<table border="0" width="100%">
<tbody>
  <tr>
    <th width="30%"></th>
    <th width="70%"></th>
  </tr>

<!-- ================ New Researches ==================-->
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/IJCAI2019CTM/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Connectionist Temporal Modeling of Video and Language: A Joint Model for Translation and Sign Labeling</b><br>
      Dan Guo, <strong>Shengeng Tang</strong>, and Meng Wang<br>
      International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2019
      <br>
      [<a href="https://www.ijcai.org/proceedings/2019/106" target="_blank">Link</a>]
      [<a href="./publications/IJCAI2019CTM/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/IJCAI2019CTM/bib.html" target="_blank">BibTex</a>]
      [<a href="./publications/IJCAI2019CTM/slides.pdf" target="_blank">Slides</a>]
      [<a href="./publications/IJCAI2019CTM/poster.pdf" target="_blank">Poster</a>]
    </td>
  </tr> 
	
<!--   <tr>
    <td>
      <div align="left">
        <img src="./publications/JSJKX2021Review/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>手语识别、翻译与生成综述</b><br>
      <b>Review of Sign Language Recognition, Translation and Generation</b><br>
      郭丹, <strong>唐申庚</strong>, 洪日昌, 汪萌<br>
      计算机科学 (Computer Science), 2021
      <br>
      [<a href="https://www.jsjkx.com/CN/10.11896/jsjkx.210100227" target="_blank">Link</a>]
      [<a href="./publications/JSJKX2021Review/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/JSJKX2021Review/bib.html" target="_blank">BibTex</a>]
    </td>
  </tr> -->
	
  <tr>
    <td>
      <div align="left">
        <img src="./publications/TMM2021MSeqGraph/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Graph-Based Multimodal Sequential Embedding for Sign Language Translation</b><br>
      <strong>Shengeng Tang</strong>, Dan Guo, Richang Hong, and Meng Wang<br>
      IEEE Transactions on Multimedia (<strong>TMM</strong>), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/abstract/document/9556136" target="_blank">Link</a>]
      [<a href="./publications/TMM2021MSeqGraph/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/TMM2021MSeqGraph/bib.html" target="_blank">BibTex</a>]
    </td>
  </tr>
	
  <tr>
    <td>
      <div align="left">
        <img src="./publications/ACMMM2022GEN/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Gloss Semantic-Enhanced Network with Online Back-Translation for Sign Language Production</b><br>
      <strong>Shengeng Tang</strong>, Richang Hong, Dan Guo, and Meng Wang<br>
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022
      <br>
      [<a href="https://dl.acm.org/doi/10.1145/3503161.3547830" target="_blank">Link</a>]
      [<a href="./publications/ACMMM2022GEN/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/ACMMM2022GEN/bib.html" target="_blank">BibTex</a>]
      [<a href="./publications/ACMMM2022GEN/poster.pdf" target="_blank">Poster</a>]
      [<a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3547830&file=MM22-fp0365.mp4" target="_blank">Video</a>]
    </td>
  </tr>

  <tr>
    <td>
      <div align="left">
        <img src="./publications/ACMMM2023EPAN/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Emotion-Prior Awareness Network for Emotional Video Captioning</b><br>
      Peipei Song, Dan Guo, Xun Yang, <strong>Shengeng Tang</strong>, Erkun Yang, and Meng Wang<br>
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2023
      <br>
      [<a href="https://dl.acm.org/doi/10.1145/3581783.3611726" target="_blank">Link</a>]
      [<a href="./publications/ACMMM2023EPAN/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/ACMMM2023EPAN/bib.html" target="_blank">BibTex</a>]
<!--       [<a href="./publications/ACMMM2023EPAN/poster.pdf" target="_blank">Poster</a>] -->
<!--       [<a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3547830&file=MM22-fp0365.mp4" target="_blank">Video</a>] -->
    </td>
  </tr>

<!--   <tr>
    <td>
      <div align="left">
        <img src="./publications/RGZN2023SL/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>基于智能生成技术的手语数字人发展现状与趋势</b><br>
      <b>Development Status and Trend of Sign Language Digital Human Based on Intelligent Generation Technology</b><br>
      <strong>唐申庚</strong>, 修雪玉, 郭丹, 洪日昌<br>
      人工智能 (Artificial Intelligence View), 2023
      <br>
      [<a href="https://kns.cnki.net/kcms/detail/detail.aspx?filename=DKJS202304003&dbname=cjfdtotal&dbcode=CJFD&v=MTY4MjdVN3pzT1QzaVFyUmN6RnJDVVI3bWZiK1JtRnlqa1Y3dk9JU2JCZmJHNEhOTE1xNDlGWjRSNkRnOC96aFk=" target="_blank">Link</a>]
      [<a href="./publications/RGZN2023SL/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/RGZN2023SL/bib.html" target="_blank">BibTex</a>]
    </td>
  </tr> -->
	
  <tr>
    <td>
      <div align="left">
        <img src="./publications/TOMM2024GCDM/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Gloss-driven Conditional Diffusion Models for Sign Language Production</b><br>
      <strong>Shengeng Tang</strong>, Feng Xue, Jingjing Wu, Shuo Wang, and Richang Hong<br>
      ACM Transactions on Multimedia Computing, Communications, and Applications (<strong>TOMM</strong>), 2024
      <br>
      [<a href="https://dl.acm.org/doi/10.1145/3663572" target="_blank">Link</a>]
      [<a href="./publications/TOMM2024GCDM/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/TOMM2024GCDM/bib.html" target="_blank">BibTex</a>]
    </td>
  </tr>
	
</tbody>
</table>


<!-- ================ Publications ==================-->
<h2 id="publications">Publications</h2>
    <p class="textBlock">
        <b>Conference papers:</b>
        <ol>
            <li>Dan Guo, <strong>Shengeng Tang</strong>, and Meng Wang, "Connectionist Temporal Modeling of Video and Language: a Joint Model for Translation and Sign Labeling", <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, 2019: 751-757.
                [<a href="https://www.ijcai.org/Proceedings/2019/106", target="_blank">Link</a>][<a href="./publications/IJCAI2019CTM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/IJCAI2019CTM/bib.html", target="_blank">BibTeX</a>]</li>
            <li><strong>Shengeng Tang</strong>, Richang Hong, Dan Guo, and Meng Wang, "Gloss Semantic-Enhanced Network with Online Back-Translation for Sign Language Production", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2022: 5630-5638. 
		[<a href="https://dl.acm.org/doi/10.1145/3503161.3547830", target="_blank">Link</a>][<a href="./publications/ACMMM2022GEN/paper.pdf" target="_blank">PDF</a>][<a href="./publications/ACMMM2022GEN/bib.html", target="_blank">BibTeX</a>]</li>
	    <li>Peipei Song, Dan Guo, Xun Yang, <strong>Shengeng Tang</strong>, Erkun Yang, and Meng Wang, "Emotion-Prior Awareness Network for Emotional Video Captioning", <i>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</i>, 2023: 589-600. 
		[<a href="https://dl.acm.org/doi/10.1145/3581783.3611726", target="_blank">Link</a>][<a href="./publications/ACMMM2023EPAN/paper.pdf" target="_blank">PDF</a>][<a href="./publications/ACMMM2023EPAN/bib.html", target="_blank">BibTeX</a>]</li>
	    <li>Jingjing Wu, Yunkai Zhang, Xi Zhou, <strong>Shengeng Tang</strong>, and Yanyan Wei, "Comprehensive Survey on Person Identification: Queries, Methods, and Datasets", <i>International Conference on Multimedia Retrieval Workshop on Multimedia Object Re-Identification (<strong>ICMR-MORE</strong>)</i>, 2024: 1-6.
                [<a href="https://dl.acm.org/doi/abs/10.1145/3643490.3661805", target="_blank">Link</a>][<a href="./publications/MORE2024RID/paper.pdf", target="_blank">PDF</a>][<a href="./publications/MORE2024RID/bib.html", target="_blank">BibTeX</a>]</li>
            <li><strong>Shengeng Tang</strong>, Jiayi He, Dan Guo, Yanyan Wei, Feng Li, and Richang Hong, "Sign-IDD: Iconicity Disentangled Diffusion for Sign Language Production", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. </li>
	    <li>Ziheng Zhou, Jinxing Zhou, Wei Qian, <strong>Shengeng Tang</strong>, Xiaojun Chang, and Dan Guo, "Dense Audio-Visual Event Localization under Cross-Modal Consistency and Multi-Temporal Granularity Collaboration", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. </li>
	    <li>Wei Qian, Gaoji Su, Dan Guo, Jinxing Zhou, Xiaobai Li, Bin Hu, <strong>Shengeng Tang</strong>, and Meng Wang, "PhysDiff: Physiology-based Dynamicity Disentangled Diffusion Model for Remote Physiological Measurement", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. </li>
	    <li>Zhangbin Li, Jinxing Zhou, Jing Zhang, <strong>Shengeng Tang</strong>, Kun Li, and Dan Guo, "Patch-level Sounding Object Tracking for Audio-Visual Question Answering", <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2025. </li>
	    <li>Xu Wang, <strong>Shengeng Tang</strong>, Peipei Song, Shuo Wang, Dan Guo, and Richang Hong, "Linguistics-Vision Monotonic Consistent Network for Sign Language Production", <i>IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>)</i>, 2025. </li>
            <li>Kezhou Chen, Shuo Wang, Huixia Ben, <strong>Shengeng Tang</strong>, and Yanbin Hao, "Mixture of Multimodal Adapters for Sentiment Analysis", <i>North American Chapter of the Association for Computational Linguistics (<strong>NAACL</strong>)</i>, 2025. </li>
            <li>Jiaqi Zhao, Fei Wang, Kun Li, Yanyan Wei, <strong>Shengeng Tang</strong>, Shu Zhao, Xiao Sun, "Temporal-Frequency State Space Duality: An Efficient Paradigm for Speech Emotion Recognition", <i>IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>)</i>, 2025. </li>
        </ol>
    </p>
    <p class="textBlock">
        <b>Journal papers:</b>
        <ol>
            <li><strong>Shengeng Tang</strong>, Dan Guo, Richang Hong, and Meng Wang, "Graph-Based Multimodal Sequential Embedding for Sign Language Translation", <i>IEEE Transactions on Multimedia (<strong>TMM</strong>)</i>, 2022, 24: 4433-4445. [<a href="https://ieeexplore.ieee.org/document/9556136", target="_blank">Link</a>][<a href="./publications/TMM2021MSeqGraph/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TMM2021MSeqGraph/bib.html", target="_blank">BibTeX</a>]</li>
            <li>Peipei Song, Dan Guo, Xun Yang, <strong>Shengeng Tang</strong>, and Meng Wang, "Emotional Video Captioning with Vision-based Emotion Interpretation Network", <i>IEEE Transactions on Image Processing (<strong>TIP</strong>)</i>, 2024, 33: 1122-1135. [<a href="https://ieeexplore.ieee.org/document/10418849", target="_blank">Link</a>][<a href="./publications/TIP2024VEIN/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TIP2024VEIN/bib.html", target="_blank">BibTeX</a>]</li>
	    <li><strong>Shengeng Tang</strong>, Feng Xue, Jingjing Wu, Shuo Wang, and Richang Hong, "Gloss-driven Conditional Diffusion Models for Sign Language Production", <i>ACM Transactions on Multimedia Computing, Communications, and Applications (<strong>TOMM</strong>)</i>, 2024. [<a href="https://dl.acm.org/doi/10.1145/3663572", target="_blank">Link</a>][<a href="./publications/TOMM2024GCDM/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TOMM2024GCDM/bib.html", target="_blank">BibTeX</a>]</li>
	    <li>Zhenqiang Zhang, Kun Li, <strong>Shengeng Tang</strong>, Yanyan Wei, Fei Wang, Jinxing Zhou, and Dan Guo, "Temporal Boundary Awareness Network for Repetitive Action Counting", <i>ACM Transactions on Multimedia Computing, Communications, and Applications (<strong>TOMM</strong>)</i>, 2024.</li>
	    <li>Jingjing Wu, Richang Hong, and <strong>Shengeng Tang</strong>, "Intermediary-Generated Bridge Network for RGB-D Cross-modal Re-identification", <i>ACM Transactions on Intelligent Systems and Technology (<strong>TIST</strong>)</i>, 2024. [<a href="https://dl.acm.org/doi/10.1145/3682066", target="_blank">Link</a>][<a href="./publications/TIST2024IBN/paper.pdf", target="_blank">PDF</a>][<a href="./publications/TIST2024IBN/bib.html", target="_blank">BibTeX</a>]</li>
            <li>郭丹, <strong>唐申庚</strong>, 洪日昌, 汪萌, "手语识别、翻译与生成综述", <i>计算机科学</i>, 2021, 48(3): 60-70. [<a href="http://www.jsjkx.com/CN/10.11896/jsjkx.210100227", target="_blank">Link</a>][<a href="./publications/JSJKX2021Review/paper.pdf", target="_blank">PDF</a>][<a href="./publications/JSJKX2021Review/bib.html", target="_blank">BibTeX</a>]</li>
            <li><strong>唐申庚</strong>, 修雪玉, 郭丹, 洪日昌, "基于智能生成技术的手语数字人发展现状与趋势", <i>人工智能</i>, 2023, 4: 20-31. [<a href="https://kns.cnki.net/kcms/detail/detail.aspx?filename=DKJS202304003&dbname=cjfdtotal&dbcode=CJFD&v=MTY4MjdVN3pzT1QzaVFyUmN6RnJDVVI3bWZiK1JtRnlqa1Y3dk9JU2JCZmJHNEhOTE1xNDlGWjRSNkRnOC96aFk=">Link</a>][<a href="./publications/RGZN2023SL/paper.pdf", target="_blank">PDF</a>][<a href="./publications/RGZN2023SL/bib.html", target="_blank">BibTeX</a>]</li>
	</ol>   
    </p>
    <p class="textBlock">
        <b>Monographs:</b>
        <ol>
            <li>Dan Guo, <strong>Shengeng Tang</strong>, Richang Hong, and Meng Wang, "Sign Language Recognition", <i>Multimedia for Accessible Human Computer Interfaces</i>. Springer, Cham, 2021: 23-59. [<a href="https://link.springer.com/book/10.1007/978-3-030-70716-3", target="_blank">Link</a>][<a href="./publications/MAHCI2021SLR/paper.pdf", target="_blank">PDF</a>][<a href="./publications/MAHCI2021SLR/bib.html", target="_blank">BibTeX</a>]</li>
        </ol>   
    </p>
    <p class="textBlock">
        <b>Patents:</b>
        <ol>
            <li><strong>唐申庚</strong>; 姚骏; 王旭; 修雪玉; 董晓虎; 谭惟尹; 郭丹; 一种基于多模态语义交互增强的手语生成系统及方法, 2024-11-12, 中国, ZL202410630950.6. (授权)</li>
            <li>郭丹; <strong>唐申庚</strong>; 刘祥龙; 洪日昌; 汪萌; 一种基于图卷积的多模态融合手语识别系统及方法, 2023-3-14, 中国, ZL202010049714.7. (授权)</li>
            <li>郭丹; <strong>唐申庚</strong>; 刘祥龙; 汪萌; 一种基于多层次语义解析的手语翻译系统及方法, 2023-3-28, 中国, ZL202010103960.6. (授权)</li>
            <li>郭丹; 谷纪豪; <strong>唐申庚</strong>; 肖同欢; 曹晨曦; 宋万强; 一种基于深度智能交互的室外视障辅助方法, 2024-2-20, 中国, ZL202210371804.7. (授权)</li>
            <li>郭丹; 曹晨曦; 肖同欢; <strong>唐申庚</strong>; 谷纪豪; 黄滨; 一种基于语义分割的择优式方向偏移预警系统和方法, 2024-2-27, 中国, ZL202210374860.6. (授权)</li>
            <li>刁云峰; 姜凯超; <strong>唐申庚</strong>; 郭丹; 汪萌; 一种针对人工智能合成图像的对抗鲁棒鉴伪方法, 2024-10-23, 中国, CN202411482098.9. (授权)</li>
	    <li><strong>唐申庚</strong>; 王旭; 程乐超; 郭丹; 洪日昌; 基于跨模态语义关联学习的运动姿态生成方法, 2024-11-13, 中国, CN202411612365.X. (实审)</li>
            <li><strong>唐申庚</strong>; 肖同欢; 郭丹; 谷纪豪; 曹晨曦; 宋万强; 黄滨; 一种基于图像目标检测和视觉深度估计的碰撞预警方法, 2023-2-27, 中国, CN202310188292.5. (实审)</li>
            <li><strong>唐申庚</strong>; 宋万强; 郭丹; 黄滨; 谷纪豪; 肖同欢; 曹晨曦; 一种基于带权无向图的视障人士路线规划方法, 2023-3-6, 中国, CN202310228006.3. (实审)</li>
	    <li>郭丹; 刘泽宽; 郭义臣; <strong>唐申庚</strong>; 武梓龙; 文则涵; 陈颖男; 一种基于深度学习的WiFi手语翻译系统及方法, 2022-7-8, 中国, CN202210805408.0. (实审)</li>
	    <li>宋培培; 杨勋; 徐军军; <strong>唐申庚</strong>; 王硕; 一种基于模态间互补性挖掘的多模态情感分析方法, 2024-4-12, 中国, CN202410442083.3. (实审)</li>
	    <li>杨勋; 徐成龙; 宋培培; 郝艳宾; 唐申庚; 一种基于双网络协作的抗噪音标签图像识别方法, 2024-8-16, 中国, CN202411126873.7. (实审)</li>
        </ol>   
    </p>
    <p class="textBlock">
        <b>Software copyright:</b>
        <ol>
            <li>郭丹; <strong>唐申庚</strong>; 陈颖男; 武梓龙; 文则涵; 刘泽宽; 基于关键点估计的人体姿态卡通化系统 V1.0, 2022SR0771364, 原始取得, 全部权利, 2022-06-16.</li>
            <li><strong>唐申庚</strong>; 黄滨; 郭丹; 谷纪豪; 盲人避障出行辅助系统 V1.0, 2023SR0517944, 原始取得, 全部权利, 2023-05-05.</li>
	    <li><strong>唐申庚</strong>; 修雪玉; 郭丹; 董晓虎; 姚骏; 谢伟豪; 跨语言手语翻译系统 V1.0, 2023SR1107827, 原始取得, 全部权利, 2023-09-20.</li>
	    <li><strong>唐申庚</strong>; 周家豪; 程乐超; 郭丹; 多源数据关联查询与推荐系统 V1.0, 2024SR1773469, 原始取得, 全部权利, 2024-11-13.</li>
        </ol>   
    </p>


<!-- ================ Experience ==================-->
<h2 id="experience">Experience &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
  <ul>
    <li class="lists">2023.02-Now, Lecturer, School of Computer Science and Information Engineering (<a href="http://ci.hfut.edu.cn/" target="_blank">SCSIE</a>), Hefei University of Technology.</li>
    <li class="lists">2017.06-2022.12, Ph.D, School of Computer Science and Information Engineering (<a href="http://ci.hfut.edu.cn/" target="_blank">SCSIE</a>), Hefei University of Technology.</li>
    <li class="lists">2013.09-2017.06, B.E, College of Information and Engineering (<a href="https://cise.hunnu.edu.cn/" target="_blank">CISE</a>), Hunan Normal University. </li>
  </ul>


<!-- ================ Professional Services ==================-->
<h2 id="services">Professional Services &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
  <ul>
    <li class="lists">Editorial Board Member for Medical Artificial Intelligence (MAI), Zentime </li>
    <li class="lists">PC Member/Reviewer for 37th/38th/39th AAAI Conference on Artificial Intelligence (AAAI 2023/2024/2025) </li>
    <li class="lists">TPC Member/Reviewer for 14th/15th/16th/17th International Conference on Creative Content Technologies (CONTENT 2022~2025) </li>
    <li class="lists">Reviewer for 19th IEEE International Conference on Computer Vision (ICCV 2023) </li>
    <li class="lists">Reviewer for 36th/37th/38th IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR 2023/2024/2025) </li>
    <li class="lists">Reviewer for 30th/31st/32nd ACM International Conference on Multimedia (MM 2022/2023/2024) </li>
    <li class="lists">Reviewer for 40th ACM Conference on Human Factors in Computing Systems (CHI 2024) </li>
    <li class="lists">Reviewer for 17th/18th European Conference on Computer Vision (ECCV 2022/2024) </li>
    <li class="lists">Reviewer for 50th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025) </li>
    <li class="lists">Reviewer for 17th Asian Conference on Computer Vision (ACCV 2024) </li>
    <li class="lists">Reviewer for 19th Pacific Rim Conference on Multimedia (PCM 2018) </li>
    <li class="lists">Reviewer for IEEE Transactions on Multimedia (TMM), IEEE </li>
    <li class="lists">Reviewer for IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), IEEE </li>
    <li class="lists">Reviewer for ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), ACM </li>
    <li class="lists">Reviewer for Computer Vision and Image Understanding (CVIU), Elsevier </li>
    <li class="lists">Reviewer for Neural Networks, Elsevier </li>
    <li class="lists">Reviewer for Neurocomputing, Elsevier </li>
    <li class="lists">Reviewer for Soft Computing, Springer </li>
    <li class="lists">Reviewer for Multimedia Systems, Springer </li>
    <li class="lists">Reviewer for International Journal of Intelligent Systems, Wiley </li>
  </ul>


<!-- ================ Link ==================-->
<h2 id="link">Link &nbsp<a href="#home" style="color:#666; font-size:15px;"></a></h2>
  <ul>
    <li><a href="https://blog.csdn.net/m0_37369043/article/details/102926076" target="_blank">Conferences Links</a>: International Conferences on Machine Learning and Artificial Intelligence.</li>
    <li><a href="https://ccfddl.top/" target="_blank">CCF Conference DDLs</a>: Information Update of International Conferences Recommended by CCF.</li>
    <!--     <li><a href="./source/gpu_resources.html" target="_blank">GPU Resources</a>: Check GPU resources.</li> -->
  </ul>

<br>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">
<div align="right" style="font-family:verdana;color:#800000">&copy; Shengeng Tang 2024</div>

<br>
<div style="width:400px;margin:0 auto">
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=500&t=tt&d=GLKJ0YbC1XPmD_dMwtxEJ2ZNIQj9GZxdekjzOOtRKkY&co=72b7e8&cmn=ff5353&cmo=242ded&ct=000000'></script>
</div>
	
</div>
</body>
</html>
